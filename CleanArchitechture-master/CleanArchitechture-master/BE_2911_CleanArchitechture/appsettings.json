{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft": "Warning",
      "Microsoft.Hosting.Lifetime": "Information"
    }
  },
  "AllowedHosts": "*",
  "ConnectionStrings": {
    "ConnectionString": "Data Source=TATHANHHOANG;Initial Catalog=APICleanArchi;Persist Security Info=True;User ID=sa;Password=753159Hg#;Trust Server Certificate=True"
  },
  "Redis": {
    "ConnectionString": "localhost:6379,abortConnect=false",
    "DefaultCacheDurationInSeconds": 60
  },
  "RabbitMQ": {
    "Host": "localhost",
    "Username": "guest",
    "Password": "guest"
  },
  "Jwt": {
    "Key": "TaThanhHoangjrutgrtgstrgbrSecretKey",
    "Issuer": "tathanhhoang.com",
    "Audience": "myAPI"
  },
  "Paging": {
    "MaxTake": 500
  },
  "KafkaSettings": {
    "BootstrapServers": "kafka-broker-1:9092,kafka-broker-2:9092",
    //Đây là trường quan trọng nhất, chứa danh sách các địa chỉ (host:port) của các Kafka Broker ban đầu.
    //Ứng dụng Producer/Consumer sẽ kết nối đến một trong số các server này để lấy thông tin siêu dữ liệu (metadata) về toàn bộ Kafka Cluster (bao gồm tất cả Broker, Topic, và Partition).

    "SecurityProtocol": "Ssl",
    //Xác định giao thức bảo mật để giao tiếp
    "SslCertificateLocation": "/path/to/cert.pem"
  },

  "KafkaConsumer": {
    "TopicName": "user-events-topic",
    "GroupId": "event-processor-group-v1",
    //Tên định danh cho nhóm Consumer.Tất cả các Consumer có cùng GroupId được coi là một đơn vị logic 
    //và cùng nhau chia sẻ công việc đọc dữ liệu từ các Partition của Topic (mỗi Partition chỉ được đọc bởi một Consumer trong nhóm tại một thời điểm).
    //Consumer khác Group có thể đọc cùng một thông điệp.
    "AutoOffsetReset": "Earliest",
    //Chỉ định nơi Consumer sẽ bắt đầu đọc nếu không có Offset đã lưu (lần đầu chạy, hoặc Offset đã hết hạn).Earliest: Bắt đầu đọc từ bản ghi đầu tiên có sẵn trong Partition. 
    //(Có thể xử lý lại dữ liệu cũ).Latest: Bắt đầu đọc từ bản ghi mới nhất (sau thời điểm Consumer bắt đầu). (Bỏ qua dữ liệu cũ chưa đọc).
    "EnableAutoCommit": false,
    //Xác định việc Offset (vị trí đọc hiện tại) có được tự động lưu bởi Consumer hay không.true: Consumer tự động commit Offset theo định kỳ.
    //Đơn giản nhưng có thể dẫn đến mất hoặc xử lý trùng lặp thông điệp nếu Consumer bị lỗi giữa chừng.false: Yêu cầu ứng dụng phải Manual Commit (commit thủ công) Offset sau khi thông điệp đã được xử lý xong.
    //An toàn hơn và được khuyến nghị cho các ứng dụng quan trọng.
    "StatisticsIntervalMs": 60000
    //Khoảng thời gian (ms) để phát ra các sự kiện thống kê và thông tin hiệu suất của Consumer. Hữu ích cho việc giám sát.
  },
    
  "KafkaProducer": {
    "Acks": "All",
    //Xác định mức độ bền vững (durability) của dữ liệu. Nó cho Broker biết cần bao nhiêu xác nhận từ các Replica trước khi Producer coi thông điệp đã được gửi thành công.
    //0: Producer không chờ xác nhận. Tốc độ nhanh nhất, nhưng rủi ro mất dữ liệu cao nhất.
    //1: Producer chờ xác nhận từ Leader Partition. Tốc độ nhanh, an toàn vừa phải.
    //All (-1): Producer chờ xác nhận từ tất cả các Replica đã đồng bộ hóa (In-Sync Replicas - ISRs). 
    //      Chậm nhất, nhưng an toàn và đáng tin cậy nhất.
    "LingerMs": 10,
    //Thời gian (ms) Producer sẽ chờ để gom nhiều bản ghi thành một lô (batch) duy nhất.
    "CompressionType": "snappy"
    //Thuật toán nén được sử dụng cho các lô dữ liệu được gửi
  }
}
